{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44796102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import datetime\n",
    "from typing import Any, Dict, List, Optional, Type, Union\n",
    "\n",
    "def run_with_config(\n",
    "    script_path: str,\n",
    "    class_or_function: Optional[str] = None,\n",
    "    method: Optional[str] = None,\n",
    "    base_dir: str = '.',\n",
    "    config_filename: str = 'config.json',\n",
    "    **kwargs\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Универсальная функция для запуска Python-скрипта с параметрами через конфигурационный файл.\n",
    "    \n",
    "    Args:\n",
    "        script_path: Путь к Python-скрипту, который нужно запустить\n",
    "        class_or_function: Имя класса или функции для вызова (опционально)\n",
    "        method: Имя метода класса для вызова (для классов)\n",
    "        base_dir: Базовая директория для сохранения конфигурационного файла\n",
    "        config_filename: Имя файла конфигурации\n",
    "        **kwargs: Любые параметры, которые нужно передать в скрипт\n",
    "        \n",
    "    Returns:\n",
    "        Код возврата процесса (0 - успешное выполнение)\n",
    "    \"\"\"\n",
    "    # Конвертируем все datetime объекты в строки\n",
    "    processed_kwargs = {}\n",
    "    for k, v in kwargs.items():\n",
    "        if isinstance(v, datetime.date) or isinstance(v, datetime.datetime):\n",
    "            processed_kwargs[k] = v.isoformat().split('T')[0]  # Формат YYYY-MM-DD\n",
    "        else:\n",
    "            processed_kwargs[k] = v\n",
    "    \n",
    "    # Создаем конфигурацию\n",
    "    config = {\n",
    "        \"params\": processed_kwargs\n",
    "    }\n",
    "    \n",
    "    # Добавляем информацию о классе и методе, если указаны\n",
    "    if class_or_function:\n",
    "        config[\"target\"] = class_or_function\n",
    "    if method:\n",
    "        config[\"method\"] = method\n",
    "    \n",
    "    # Полный путь к конфигурационному файлу\n",
    "    config_path = os.path.join(base_dir, config_filename)\n",
    "    \n",
    "    # Сохраняем конфигурацию в файл\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"Конфигурация сохранена в {config_path}\")\n",
    "    \n",
    "    # Проверяем существование скрипта\n",
    "    if not os.path.exists(script_path):\n",
    "        raise FileNotFoundError(f\"Скрипт {script_path} не найден\")\n",
    "    \n",
    "    # Запускаем скрипт с указанием файла конфигурации\n",
    "    command = [sys.executable, script_path, '--config', config_path]\n",
    "    \n",
    "    print(\"Запуск команды:\", \" \".join(command))\n",
    "    \n",
    "    # Запускаем процесс и перенаправляем вывод\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                              universal_newlines=True, bufsize=1)\n",
    "    \n",
    "    # Выводим результаты в реальном времени\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    \n",
    "    # Ждем завершения процесса\n",
    "    process.wait()\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        print(\"\\nПроцесс успешно завершен\")\n",
    "    else:\n",
    "        print(f\"\\nОшибка при выполнении процесса, код: {process.returncode}\")\n",
    "    \n",
    "    return process.returncode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "85a5528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinkoff.invest\n",
    "from tinkoff.invest import PortfolioRequest, PortfolioPosition, Client, RequestError, CandleInterval, HistoricCandle, \\\n",
    "    OrderType, OrderDirection, Quotation, InstrumentIdType, InstrumentStatus\n",
    "from tinkoff.invest.services import InstrumentsService\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import importlib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "sys.path.append('/Users/aeshef/Documents/GitHub/kursach/pys')\n",
    "\n",
    "#####\n",
    "\n",
    "import market_data\n",
    "importlib.reload(market_data)\n",
    "from market_data import MarketDataManager\n",
    "\n",
    "######\n",
    "\n",
    "import fundamental_data\n",
    "importlib.reload(fundamental_data)\n",
    "from fundamental_data import FinamFinancialParser\n",
    "\n",
    "######\n",
    "\n",
    "import tech_analysis\n",
    "importlib.reload(tech_analysis)\n",
    "from tech_analysis import TechAnalysisPipeline\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "import news_pipeline\n",
    "importlib.reload(news_pipeline)\n",
    "from news_pipeline import NewsPipeline\n",
    "\n",
    "######\n",
    "\n",
    "import data_integration\n",
    "importlib.reload(data_integration)\n",
    "from data_integration import DataIntegrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ae222",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cbc6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"t.GVEetX09IVL9qECDUhjThfpg5TrE2Oxw9cUnAIOxcHh35M2sv1YMy9LBfkt73F3WlV_Ik08etZOVrUNI8StLBQ\"\n",
    "kursach_directory_path = \"/Users/aeshef/Documents/GitHub/kursach\"\n",
    "your_directory_path = \"/Users/aeshef/Documents/GitHub/kursach/data\"\n",
    "\n",
    "tickers = pd.read_csv(f\"{your_directory_path}/tickers.csv\")\n",
    "tickers_list = [\n",
    "    'SBER',  # Сбербанк\n",
    "    'GAZP',  # Газпром\n",
    "    'LKOH',  # Лукойл\n",
    "    'GMKN',  # ГМК \"Норильский никель\"\n",
    "    'ROSN',  # Роснефть\n",
    "    'TATN',  # Татнефть\n",
    "    'MTSS',  # МТС\n",
    "    'ALRS',  # АК Алроса\n",
    "    'SNGS',  # Сургутнефтегаз\n",
    "    'VTBR',  # ВТБ\n",
    "    'NVTK',  # Новатэк\n",
    "    'MVID',  # М.Видео\n",
    "    'PHOR',  # ФосАгро\n",
    "    'SIBN',  # Сибнефть\n",
    "    'AFKS',  # АФК Система\n",
    "    'MAGN',  # Магнитогорский металлургический комбинат\n",
    "    'RUAL'   # Русал\n",
    "]\n",
    "\n",
    "start_date=\"2024-06-01\"\n",
    "end_date=\"2025-04-21\"\n",
    "timeframe=\"1h\"\n",
    "\n",
    "YOUR_API_ID = 28994010\n",
    "YOUR_API_HASH = \"6e7a57fdfe1a10b0a3434104b42badf2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba082bb5",
   "metadata": {},
   "source": [
    "## Initial parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c00821de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manager = MarketDataManager(token, your_directory_path)\n",
    "\n",
    "# multi_ticker_data = manager.get_data_for_multiple_tickers(\n",
    "#     tickers=tickers_list, \n",
    "#     start_date=start_date, \n",
    "#     end_date=end_date, \n",
    "#     timeframe=timeframe\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627cad2",
   "metadata": {},
   "source": [
    "## Fundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "392f9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# for ticker in tickers_list:\n",
    "#     logging.info(f\"\\n========== Processing {ticker} ==========\\n\")\n",
    "#     parser = FinamFinancialParser(ticker)   # ПЕРЕДАЁШЬ тикер!\n",
    "#     financial_data_df = parser.parse_financial_data()\n",
    "#     if financial_data_df is not None:\n",
    "#         parser.save_to_csv(financial_data_df)\n",
    "#         logging.info(f\"Финансовые данные для {ticker} сохранены успешно\")\n",
    "#     else:\n",
    "#         logging.warning(f\"No data found for {ticker}. Проверь логи, html и soup-просмотр!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcdf821",
   "metadata": {},
   "source": [
    "## Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b47774f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== НАЧАЛО ТЕХНИЧЕСКОГО АНАЛИЗА ===\n",
      "\n",
      "Обработка тикера: GAZP\n",
      "Используем файл: GAZP_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/GAZP/tech_analysis/GAZP_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/GAZP/tech_analysis/GAZP_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/GAZP/tech_analysis/GAZP_MACD.png\n",
      "\n",
      "Обработка тикера: SBER\n",
      "Используем файл: SBER_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SBER/tech_analysis/SBER_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SBER/tech_analysis/SBER_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SBER/tech_analysis/SBER_MACD.png\n",
      "\n",
      "Обработка тикера: LKOH\n",
      "Используем файл: LKOH_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/LKOH/tech_analysis/LKOH_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/LKOH/tech_analysis/LKOH_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/LKOH/tech_analysis/LKOH_MACD.png\n",
      "\n",
      "Обработка тикера: GMKN\n",
      "Используем файл: GMKN_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/GMKN/tech_analysis/GMKN_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/GMKN/tech_analysis/GMKN_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/GMKN/tech_analysis/GMKN_MACD.png\n",
      "\n",
      "Обработка тикера: ROSN\n",
      "Используем файл: ROSN_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/ROSN/tech_analysis/ROSN_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/ROSN/tech_analysis/ROSN_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/ROSN/tech_analysis/ROSN_MACD.png\n",
      "\n",
      "Обработка тикера: TATN\n",
      "Используем файл: TATN_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/TATN/tech_analysis/TATN_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/TATN/tech_analysis/TATN_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/TATN/tech_analysis/TATN_MACD.png\n",
      "\n",
      "Обработка тикера: MTSS\n",
      "Используем файл: MTSS_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MTSS/tech_analysis/MTSS_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MTSS/tech_analysis/MTSS_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MTSS/tech_analysis/MTSS_MACD.png\n",
      "\n",
      "Обработка тикера: ALRS\n",
      "Используем файл: ALRS_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/ALRS/tech_analysis/ALRS_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/ALRS/tech_analysis/ALRS_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/ALRS/tech_analysis/ALRS_MACD.png\n",
      "\n",
      "Обработка тикера: SNGS\n",
      "Используем файл: SNGS_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SNGS/tech_analysis/SNGS_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SNGS/tech_analysis/SNGS_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SNGS/tech_analysis/SNGS_MACD.png\n",
      "\n",
      "Обработка тикера: VTBR\n",
      "Используем файл: VTBR_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/VTBR/tech_analysis/VTBR_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/VTBR/tech_analysis/VTBR_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/VTBR/tech_analysis/VTBR_MACD.png\n",
      "\n",
      "Обработка тикера: NVTK\n",
      "Используем файл: NVTK_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/NVTK/tech_analysis/NVTK_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/NVTK/tech_analysis/NVTK_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/NVTK/tech_analysis/NVTK_MACD.png\n",
      "\n",
      "Обработка тикера: POLY\n",
      "Директория для тикера POLY не найдена. Пропускаем!\n",
      "\n",
      "Обработка тикера: MVID\n",
      "Используем файл: MVID_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MVID/tech_analysis/MVID_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MVID/tech_analysis/MVID_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MVID/tech_analysis/MVID_MACD.png\n",
      "\n",
      "Обработка тикера: PHOR\n",
      "Используем файл: PHOR_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/PHOR/tech_analysis/PHOR_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/PHOR/tech_analysis/PHOR_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/PHOR/tech_analysis/PHOR_MACD.png\n",
      "\n",
      "Обработка тикера: SIBN\n",
      "Используем файл: SIBN_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SIBN/tech_analysis/SIBN_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SIBN/tech_analysis/SIBN_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/SIBN/tech_analysis/SIBN_MACD.png\n",
      "\n",
      "Обработка тикера: AFKS\n",
      "Используем файл: AFKS_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/AFKS/tech_analysis/AFKS_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/AFKS/tech_analysis/AFKS_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/AFKS/tech_analysis/AFKS_MACD.png\n",
      "\n",
      "Обработка тикера: MAGN\n",
      "Используем файл: MAGN_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MAGN/tech_analysis/MAGN_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MAGN/tech_analysis/MAGN_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/MAGN/tech_analysis/MAGN_MACD.png\n",
      "\n",
      "Обработка тикера: RUAL\n",
      "Используем файл: RUAL_2024-06-01_2025-04-20.parquet\n",
      "Index(['date', 'open', 'close', 'low', 'high', 'volume'], dtype='object')\n",
      "Сохранен CSV с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/RUAL/tech_analysis/RUAL_tech_indicators.csv\n",
      "Сохранен график цены с индикаторами: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/RUAL/tech_analysis/RUAL_price_indicators.png\n",
      "Сохранен график MACD: /Users/aeshef/Documents/GitHub/kursach/data/processed_data/RUAL/tech_analysis/RUAL_MACD.png\n",
      "Сводный отчет сохранен в /Users/aeshef/Documents/GitHub/kursach/data/processed_data/tech_analysis_summary.txt\n",
      "=== ТЕХНИЧЕСКИЙ АНАЛИЗ ЗАВЕРШЕН ===\n"
     ]
    }
   ],
   "source": [
    "pipeline = TechAnalysisPipeline(base_dir=\"/Users/aeshef/Documents/GitHub/kursach\")\n",
    "pipeline.run_pipeline(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b61040",
   "metadata": {},
   "source": [
    "## News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af4b1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Конфигурация сохранена в /Users/aeshef/Documents/GitHub/kursach/news_pipeline_config.json\n",
      "Запуск команды: /Library/Developer/CommandLineTools/usr/bin/python3 /Users/aeshef/Documents/GitHub/kursach/pys/news_pipeline.py --config /Users/aeshef/Documents/GitHub/kursach/news_pipeline_config.json\n",
      "Запуск pipeline.run_pipeline с параметрами: {'tickers': ['SBER', 'GAZP', 'LKOH', 'GMKN', 'ROSN', 'TATN', 'MTSS', 'ALRS', 'SNGS', 'VTBR', 'NVTK', 'MVID', 'PHOR', 'SIBN', 'AFKS', 'MAGN', 'RUAL'], 'collect_telegram': True, 'telegram_api_id': 28994010, 'telegram_api_hash': '6e7a57fdfe1a10b0a3434104b42badf2', 'telegram_channel': 'cbrstocks', 'telegram_limit': 10000, 'start_date': datetime.date(2024, 6, 1), 'end_date': datetime.date(2025, 4, 21), 'use_cached_telegram': True}\n",
      "2025-04-22 02:19:57 - NewsPipeline - INFO - Запуск пайплайна анализа новостей для 17 тикеров\n",
      "2025-04-22 02:19:57 - NewsPipeline - INFO - Диапазон дат: 2024-06-01 - 2025-04-21\n",
      "2025-04-22 02:19:57 - pymorphy2.opencorpora_dict.wrapper - INFO - Loading dictionaries from /Users/aeshef/Library/Python/3.9/lib/python/site-packages/pymorphy2_dicts_ru/data\n",
      "2025-04-22 02:19:57 - pymorphy2.opencorpora_dict.wrapper - INFO - format: 2.4, revision: 417127, updated: 2020-10-11T15:05:51.070345\n",
      "2025-04-22 02:19:57 - NewsPipeline - INFO - === СБОР ДАННЫХ ИЗ TELEGRAM ===\n",
      "2025-04-22 02:19:57 - telethon.network.mtprotosender - INFO - Connecting to 149.154.167.51:443/TcpFull...\n",
      "2025-04-22 02:19:57 - telethon.network.mtprotosender - INFO - Connection to 149.154.167.51:443/TcpFull complete!\n",
      "Подключение к Telegram...\n",
      "2025-04-22 02:19:57 - NewsPipeline - INFO - Получена сущность канала: Сигналы РЦБ\n",
      "2025-04-22 02:19:58 - NewsPipeline - INFO - Получено 50 сообщений...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscript_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/aeshef/Documents/GitHub/kursach/pys/news_pipeline.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_or_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNewsPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_pipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkursach_directory_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnews_pipeline_config.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtickers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtickers_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollect_telegram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtelegram_api_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYOUR_API_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtelegram_api_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYOUR_API_HASH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtelegram_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcbrstocks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtelegram_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cached_telegram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 72\u001b[0m, in \u001b[0;36mrun_with_config\u001b[0;34m(script_path, class_or_function, method, base_dir, config_filename, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(command, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT, \n\u001b[1;32m     69\u001b[0m                           universal_newlines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bufsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Выводим результаты в реальном времени\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m process\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(line, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Ждем завершения процесса\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "run_with_config(\n",
    "    script_path=\"/Users/aeshef/Documents/GitHub/kursach/pys/news_pipeline.py\",\n",
    "    class_or_function=\"NewsPipeline\",\n",
    "    method=\"run_pipeline\",\n",
    "    base_dir=kursach_directory_path,\n",
    "    config_filename=\"news_pipeline_config.json\",\n",
    "    \n",
    "    tickers=tickers_list,\n",
    "    collect_telegram=True,\n",
    "    telegram_api_id=YOUR_API_ID,\n",
    "    telegram_api_hash=YOUR_API_HASH,\n",
    "    telegram_channel=\"cbrstocks\",\n",
    "    telegram_limit=10000,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    use_cached_telegram=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a6974946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка тикера SBER...\n",
      "  - Обнаружено 1186 пропущенных значений для SBER\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера GAZP...\n",
      "  - Обнаружено 1050 пропущенных значений для GAZP\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера LKOH...\n",
      "  - Обнаружено 1050 пропущенных значений для LKOH\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера GMKN...\n",
      "  - Обнаружено 1278 пропущенных значений для GMKN\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера ROSN...\n",
      "  - Обнаружено 1050 пропущенных значений для ROSN\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера TATN...\n",
      "  - Обнаружено 1050 пропущенных значений для TATN\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера MTSS...\n",
      "  - Обнаружено 1363 пропущенных значений для MTSS\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера ALRS...\n",
      "  - Обнаружено 1154 пропущенных значений для ALRS\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера SNGS...\n",
      "  - Обнаружено 1050 пропущенных значений для SNGS\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера VTBR...\n",
      "  - Обнаружено 1339 пропущенных значений для VTBR\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера NVTK...\n",
      "  - Обнаружено 1050 пропущенных значений для NVTK\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера MVID...\n",
      "  - Обнаружено 2388 пропущенных значений для MVID\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера PHOR...\n",
      "  - Обнаружено 1345 пропущенных значений для PHOR\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера SIBN...\n",
      "  - Обнаружено 1050 пропущенных значений для SIBN\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера AFKS...\n",
      "  - Обнаружено 1248 пропущенных значений для AFKS\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера MAGN...\n",
      "  - Обнаружено 1161 пропущенных значений для MAGN\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Обработка тикера RUAL...\n",
      "  - Обнаружено 1519 пропущенных значений для RUAL\n",
      "  - Пропущенные значения заполнены методом zero\n",
      "Данные успешно объединены и сохранены в /Users/aeshef/Documents/GitHub/kursach/data/combined_features_fixed.csv\n",
      "Форма объединенного датасета: (5473, 384)\n",
      "Количество уникальных тикеров: 17\n",
      "Количество пропущенных значений: 0\n"
     ]
    }
   ],
   "source": [
    "integrator = DataIntegrator(base_path='/Users/aeshef/Documents/GitHub/kursach/data/processed_data', nan_fill_method='zero')  # Замените на 'median' или 'mean', если нужно\n",
    "\n",
    "# Загружаем и объединяем данные для всех тикеров\n",
    "combined_data = integrator.load_multiple_tickers(tickers=tickers_list)\n",
    "\n",
    "# Проверка результата\n",
    "if not combined_data.empty:\n",
    "    # Сохраняем объединенные данные\n",
    "    output_path = '/Users/aeshef/Documents/GitHub/kursach/data/combined_features_fixed.csv'\n",
    "    combined_data.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Данные успешно объединены и сохранены в {output_path}\")\n",
    "    print(f\"Форма объединенного датасета: {combined_data.shape}\")\n",
    "    print(f\"Количество уникальных тикеров: {combined_data['ticker'].nunique()}\")\n",
    "    \n",
    "    # Проверка на пропущенные значения\n",
    "    null_count = combined_data.isnull().sum().sum()\n",
    "    print(f\"Количество пропущенных значений: {null_count}\")\n",
    "else:\n",
    "    print(\"Не удалось создать объединенный датасет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9e78f8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 4506     0.0\n",
       "4507     0.0\n",
       "4508    99.0\n",
       "4509    99.0\n",
       "4510    99.0\n",
       "        ... \n",
       "3216    99.0\n",
       "3217     0.0\n",
       "3218     0.0\n",
       "3219     0.0\n",
       "3220     0.0\n",
       "Name: days_to_cbr_meeting, Length: 5473, dtype: float64>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[\"days_to_cbr_meeting\"].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fa56a38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'SMA_20', 'EMA_20',\n",
       "       'WMA', 'RSI_14',\n",
       "       ...\n",
       "       'sentiment_zscore_7d_std14', 'sentiment_zscore_14d_ma3',\n",
       "       'sentiment_zscore_14d_ma7', 'sentiment_zscore_14d_ma14',\n",
       "       'sentiment_zscore_14d_ma30', 'sentiment_zscore_14d_std7',\n",
       "       'sentiment_zscore_14d_std14', 'sentiment_return_corr',\n",
       "       'news_count_volatility', 'ticker'],\n",
       "      dtype='object', length=384)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964371c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
