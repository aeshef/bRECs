# /–¢–≤–æ–π_–ü—Ä–æ–µ–∫—Ç_Kursach/scheduler/main.py
import logging
import os
import sys
import json
from pathlib import Path
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.executors.pool import ThreadPoolExecutor as APSchedulerThreadPoolExecutor
from dotenv import load_dotenv
from telegram import Bot, TelegramError

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ü—É—Ç–µ–π ---
try:
    PROJECT_ROOT = Path(__file__).parent.parent.resolve()
    if str(PROJECT_ROOT) not in sys.path: sys.path.insert(0, str(PROJECT_ROOT))
    PYS_PATH = PROJECT_ROOT / 'pys'
    if PYS_PATH.exists() and str(PYS_PATH) not in sys.path: sys.path.insert(0, str(PYS_PATH))
    from pys.utils.path_helper import get_project_root, get_logs_path
    LOGS_PATH = get_logs_path()
except ImportError:
    print("Fatal Error: Could not import path_helper in scheduler.")
    sys.exit(1)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ .env ---
env_path = PROJECT_ROOT / '.env'
if env_path.exists(): load_dotenv(dotenv_path=env_path)
else: print(f"Warning: .env file not found at {env_path}")

ENV_TYPE = os.getenv('ENV_TYPE', 'local')
BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
try:
    ADMIN_IDS = json.loads(os.getenv('TELEGRAM_ADMIN_IDS', '[]'))
    if not isinstance(ADMIN_IDS, list): ADMIN_IDS = []
except Exception: ADMIN_IDS = []
SCHEDULER_MAX_WORKERS = int(os.getenv('SCHEDULER_MAX_WORKERS', '2')) # –ö–æ–ª-–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —é–∑–µ—Ä–æ–≤

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
log_file_path = LOGS_PATH / 'scheduler.log'
logging.basicConfig(
    level=logging.INFO, # –ú–µ–Ω—å—à–µ –ª–æ–≥–æ–≤ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
    format='%(asctime)s - %(name)s - %(levelname)s - [%(threadName)s] - %(message)s',
    handlers=[
        logging.FileHandler(log_file_path),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)
logging.getLogger('apscheduler').setLevel(logging.WARNING)
logging.getLogger('sqlalchemy.engine').setLevel(logging.WARNING)

# --- –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ü—Ä–æ–µ–∫—Ç–∞ ---
try:
    from db.models import SessionLocal, User, engine as db_engine
    from db import crud
    from core.pipeline_runner import run_global_data_update, run_user_portfolio_update
    from tg_bot.notification_sender import send_result_notification
except ImportError as e:
    logger.critical(f"Fatal Error: Could not import project modules. Error: {e}")
    sys.exit(1)

# --- –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ê–¥–º–∏–Ω–∞ ---
def notify_admin(message: str):
    if not BOT_TOKEN or not ADMIN_IDS: return
    try:
        bot = Bot(token=BOT_TOKEN)
        full_message = f"üîî *Scheduler Alert* ({ENV_TYPE})\n\n{message}"
        for admin_id in ADMIN_IDS:
             try:
                  bot.send_message(chat_id=admin_id, text=full_message, parse_mode='Markdown')
             except TelegramError as te:
                  logger.warning(f"Failed to send alert to admin {admin_id}: {te}")
    except Exception as e:
        logger.error(f"Failed to initialize bot for admin notification: {e}")


# --- –§—É–Ω–∫—Ü–∏–∏ –ó–∞–¥–∞—á –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ ---
# –ü—É–ª –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
portfolio_update_executor = ThreadPoolExecutor(max_workers=SCHEDULER_MAX_WORKERS,
                                               thread_name_prefix='PortfolioUpdateWorker')

def trigger_global_data_update():
    """–ó–∞–¥–∞—á–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö."""
    logger.info("SCHEDULER JOB STARTED: Running global data update...")
    start_time = time.monotonic()
    try:
        success = run_global_data_update()
        duration = time.monotonic() - start_time
        if success:
            logger.info(f"SCHEDULER JOB FINISHED: Global data update successful. Duration: {duration:.2f}s")
        else:
            logger.error("SCHEDULER JOB FAILED: Global data update returned False.")
            notify_admin("‚ùå Global data update job failed. Check scheduler logs.")
    except Exception as e:
        duration = time.monotonic() - start_time
        logger.exception(f"SCHEDULER JOB FAILED: Exception during global data update job after {duration:.2f}s.")
        notify_admin(f"üí• Exception in global data update job: {e}")

def trigger_single_user_update_task(user_id: int, telegram_id: int):
     """
     –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —é–∑–µ—Ä–∞ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ.
     –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –±—É–¥–µ—Ç –∑–∞–ø—É—â–µ–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –∏–∑ ThreadPoolExecutor.
     """
     logger.info(f"PortfolioUpdateWorker started for user_id={user_id}")
     start_time = time.monotonic()
     bot_instance = None

     try:
         # --- –ó–∞–ø—É—Å–∫ –Ø–¥—Ä–∞ ---
         final_weights, final_metrics, significant_changes = run_user_portfolio_update(user_id, is_initial=False)
         duration = time.monotonic() - start_time

         # --- –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ) ---
         if final_weights is not None and significant_changes:
             logger.info(f"Portfolio update success for user {user_id} with changes. Duration: {duration:.2f}s. Notifying...")
             if BOT_TOKEN:
                 try:
                     bot_instance = Bot(token=BOT_TOKEN)
                     send_result_notification(
                         bot=bot_instance, chat_id=telegram_id, success=True,
                         weights=final_weights, metrics=final_metrics,
                         is_initial=False, significant_changes=True
                     )
                     logger.info(f"Notification sent successfully to user {user_id}.")
                 except TelegramError as te:
                      logger.error(f"TelegramError sending notification to user {user_id}: {te}")
                 except Exception as notify_err:
                      logger.exception(f"Error sending notification to user {user_id}: {notify_err}")
             else:
                 logger.warning(f"BOT_TOKEN not found, cannot send notification to user {user_id}.")

         elif final_weights is None:
              logger.error(f"PortfolioUpdateWorker FAILED for user {user_id}. Duration: {duration:.2f}s. No notification sent.")
              # –ú–æ–∂–Ω–æ —É–≤–µ–¥–æ–º–∏—Ç—å –∞–¥–º–∏–Ω–∞
              # notify_admin(f" portfolio update failed for user_id: {user_id}")
         else:
             logger.info(f"Portfolio update for user {user_id} successful, no significant changes. Duration: {duration:.2f}s.")

     except Exception as e:
          duration = time.monotonic() - start_time
          logger.exception(f"PortfolioUpdateWorker FAILED with exception for user_id={user_id} after {duration:.2f}s.")
          # –£–≤–µ–¥–æ–º–∏—Ç—å –∞–¥–º–∏–Ω–∞?
          # notify_admin(f"üí• Exception in single user update task for user_id={user_id}: {e}")
     finally:
          logger.info(f"PortfolioUpdateWorker finished for user_id={user_id}")


def trigger_weekly_user_updates():
    """–ó–∞–¥–∞—á–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö —é–∑–µ—Ä–æ–≤."""
    logger.info("SCHEDULER JOB STARTED: Running weekly user portfolio updates...")
    start_time = time.monotonic()
    active_users = []
    db = SessionLocal()
    try:
        active_users = crud.get_active_users(db)
        logger.info(f"Found {len(active_users)} active users for weekly update.")
    except Exception as e:
        logger.exception("Error fetching active users from DB.")
        notify_admin(f"üí• Error fetching active users for weekly update: {e}")
        return
    finally:
        db.close()

    if not active_users:
        logger.info("No active users found. Skipping weekly updates.")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    futures = {}
    submitted_count = 0
    for user in active_users:
        if user.id and user.telegram_id:
             try:
                  future = portfolio_update_executor.submit(trigger_single_user_update_task, user.id, user.telegram_id)
                  futures[future] = user.id # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫
                  submitted_count += 1
             except Exception as submit_err:
                  logger.error(f"Failed to submit update task for user_id={user.id}: {submit_err}")
        else:
             logger.warning(f"Skipping user with invalid id or telegram_id: {user.id if user else 'Unknown'}")

    logger.info(f"Submitted {submitted_count} user update tasks to executor.")

    # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
    errors_count = 0
    completed_count = 0
    for future in as_completed(futures):
         user_id_err = futures[future]
         try:
             future.result()
             completed_count += 1
         except Exception as exc:
             logger.error(f"Task for user_id={user_id_err} generated an exception: {exc}", exc_info=False) # –ù–µ –¥—É–±–ª–∏—Ä—É–µ–º traceback
             errors_count += 1

    duration = time.monotonic() - start_time
    logger.info(f"SCHEDULER JOB FINISHED: Weekly user updates processed. Completed: {completed_count}, Errors: {errors_count}. Total Duration: {duration:.2f}s")
    if errors_count > 0:
         notify_admin(f"‚ö†Ô∏è Weekly portfolio update finished with {errors_count} errors out of {submitted_count} submitted tasks.")


# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –ó–∞–ø—É—Å–∫ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ ---
if __name__ == "__main__":
    logger.info(f"--- Starting Scheduler --- mode: {ENV_TYPE} ---")

    # –•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á (—á—Ç–æ–±—ã –Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å –∏—Ö –∑–∞–Ω–æ–≤–æ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º SQLAlchemyJobStore, —É–∫–∞–∑—ã–≤–∞—è URL –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –ë–î
    try:
        from db.models import DATABASE_URL as DB_URL_FOR_STORE # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º URL –∏–∑ –º–æ–¥–µ–ª–µ–π
        if 'sqlite' in DB_URL_FOR_STORE:
             # –î–ª—è SQLite –ø—É—Ç—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–º
             db_path = DB_URL_FOR_STORE.split('///')[1]
             if not os.path.isabs(db_path):
                   db_path = str(PROJECT_ROOT / db_path)
             jobstore_url = f'sqlite:///{db_path}'
        else:
             jobstore_url = DB_URL_FOR_STORE
        logger.info(f"Using database job store: {jobstore_url.split('@')[1] if '@' in jobstore_url else jobstore_url}")
        jobstores = {
            'default': SQLAlchemyJobStore(url=jobstore_url, tablename='apscheduler_jobs')
        }
    except Exception as store_err:
         logger.exception("Failed to configure SQLAlchemyJobStore. Using default MemoryJobStore.")
         jobstores = {'default': None}

    executors = {
         'default': APSchedulerThreadPoolExecutor(5)
    }
    job_defaults = {
        'coalesce': True, # –ù–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–¥—Ä—è–¥
        'max_instances': 1, # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, —á—Ç–æ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
        'misfire_grace_time': 3600 # 1 —á–∞—Å –Ω–∞ –∑–∞–ø—É—Å–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏
    }

    try:
         import pytz
         timezone = pytz.timezone('Europe/Moscow')
    except ImportError:
         logger.warning("pytz not installed. Using system default timezone.")
         timezone = None

    scheduler = BlockingScheduler(
         jobstores=jobstores,
         executors=executors,
         job_defaults=job_defaults,
         timezone=timezone
    )

    # --- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ó–∞–¥–∞—á ---
    try:
        # 1. –ì–ª–æ–±–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–µ–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 03:05 –ø–æ –ú–°–ö)
        scheduler.add_job(
            trigger_global_data_update,
            trigger='cron',
            hour=3,
            minute=5,
            id='global_data_update_daily',
            name='Daily Global Data Update',
            replace_existing=True,
        )

        # 2. –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–π (–∫–∞–∂–¥—ã–π –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –≤ 05:05 –ø–æ –ú–°–ö)
        scheduler.add_job(
             trigger_weekly_user_updates,
             trigger='cron',
             day_of_week='mon',
             hour=5,
             minute=5,
             id='weekly_user_updates_all',
             name='Weekly User Portfolio Updates',
             replace_existing=True,
             misfire_grace_time=3600 * 3 # –î–∞–µ–º –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ (3 —á–∞—Å–∞) –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
        )

        logger.info("--- Scheduler Jobs ---")
        scheduler.print_jobs()
        logger.info("----------------------")

        logger.info("Starting scheduler event loop...")
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∞ –æ —Å—Ç–∞—Ä—Ç–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        notify_admin(f"‚úÖ Scheduler started successfully in {ENV_TYPE} mode.")

        scheduler.start()

    except (KeyboardInterrupt, SystemExit):
        logger.info("Scheduler shutdown requested.")
    except Exception as e:
        logger.critical("Fatal error starting scheduler.", exc_info=True)
        notify_admin(f"üí• FATAL ERROR starting scheduler: {e}")
    finally:
        if scheduler.running:
             logger.info("Shutting down scheduler...")
             scheduler.shutdown()
        logger.info("Shutting down portfolio update executor...")
        portfolio_update_executor.shutdown(wait=True)
        logger.info("Scheduler and executors shut down gracefully.")

